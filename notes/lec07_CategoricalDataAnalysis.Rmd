---
title: 'Lec 07: Categorical Data Analysis'
author: "MATH 456 - Spring 2016"
output:
  html_document:
    highlight: pygments
    theme: spacelab
    toc: yes
  pdf_document: default
---
```{r,echo=FALSE, warning=FALSE, message=FALSE}
library(knitr); library(rmarkdown);library(ggplot2)
library(xtable); library(dplyr)
options(xtable.comment = FALSE)
opts_chunk$set(warning=FALSE, message=FALSE, fig.height=4, fig.width=5, fig.align='center') 
```

```{r results="asis", echo=FALSE}
source("C:/Github/MATH456/stylesheets/custom.R")
```

Navbar: [[Home]](../index.html) [[Schedule]](../Schedule.html) [[Data]](../data/Datasets.html) [[Week 10 Overview]](../wk10.html) [[HW Info]](../HW_Info.html)  [[Google Group]](https://groups.google.com/forum/#!forum/csuc_stat)


# Introduction 
Up until now we have been analyzing continuous outcomes. We will now turn our
focus to methods to analyze categorical data. This will allow us to answer 
questions like the following:

* What proportion of the American public approves of the job the Supreme Court
  is doing?
* The Pew Research Center conducted a poll about support for the 2010 health 
  care law, and they used two forms of the survey question. Each respondent
  was randomly given one of the two questions. What is the difference in the
  support for respondents under the two question orderings?

The methods you learned in previous classes will be useful in these settings. 
For example, sample proportions are well characterized by a nearly normal 
distribution when certain conditions are satisfied, making it possible 
to employ the usual CI and HT tools. In other instances, such as those with 
contingency tables or when sample size conditions are not met, we will use a 
different distribution, though the core ideas remain the same.

Be sure to referece the categorical data sections of the [Data Visualization Tutorial](http://norcalbiostat.github.io/R-Bootcamp/labs/Data_Visualization_Tutorial_Full.html) or 
the [Cookbook for R](http://www.cookbook-r.com/Graphs/Bar_and_line_graphs_(ggplot2)/) for
more information and guidance on how to plot categorical data correctly. 

## Assigned Reading
* OpenIntro Lab on categorical data [[HTML]](notes/OI_Inf_for_categorical_data/html)
* OpenIntro Statistics [Free PDF Textbook](https://www.openintro.org/stat/textbook.php) Chapter 6 (6.1-6.4)
* Afifi Chapter 12 (Logistic Regression)

## Additional References 
* Mike Marin: Relative Risk and Odds Ratio https://www.youtube.com/watch?v=V_YNPQoAyCc
* An **excellent** additional textbook reference: _Categorical Data Analysis_ by Alan Agresti
* Using R for Biomedical Statistics http://a-little-book-of-r-for-biomedical-statistics.readthedocs.org/en/latest/src/biomedicalstats.html#
* Graphics
    * **New find!** Graphical Data Analysis with R http://www.gradaanwr.net/content/04-displaying-categorial-data/
    * My Data viz tutorial http://norcalbiostat.github.io/R-Bootcamp/labs/Data_Visualization_Tutorial_Full.html
    * Cookbook for R http://www.cookbook-r.com/Graphs/Bar_and_line_graphs_(ggplot2)/


#### Spam Data
This set of lecture notes uses the `spam` data set. 
```{r}
email <- read.delim("C:/Dropbox/CSUC/Data/email.txt", header=TRUE, sep="\t")
```

Two categorical variables of current interest are

* `spam` (0/1 binary indicator if a an email is flagged as spam). Converted into a Ham/Spam factor variable. 
* `number` categorical variable describing the size of the numbers contained in the email.  
    - `none`: No numbers 
    - `small`: Only values under 1 million
    - `big`: A value of 1 million or more

# Review: Inference on a single proportion 
This section is considered review and will not be covered directly in 
class. If you have never analyzed proportions in R or it has been a while 
since you took MATH 315 it is advised that you do not skip this section. 

* Open Intro: Chapter 6.1

###### Complete the OpenIntro Lab on categorical data [[HTML]](notes/OI_Inf_for_categorical_data/html) **You must have the `openintro` package installed & loaded to have access to the custom `inference()` function used in the lab.**

### Example: Examining the frequency of number sizes in emails

#### One-way Tables
A table for a single variable is called a _frequency table_. The values 
displayed represent the number of records in the data set that fall into that
particular category.
```{r}
table(email$number)
```

If we replaced the counts with percentages or proportions, the table would be
called a _relative frequency table_.

```{r}
prop.table(table(email$number))
```

We make this output more human readable as percentages by rounding the results
and multplying by 100.
```{r}
round(prop.table(table(email$number))*100,2)
```

Out of the 3921 emails in this data set, 545 (13.9%) contain big numbers, 
2827 (72.1%) contain small numbers, and 549 (14.0%) contain no numbers. 

#### One variable barcharts

The most common method to display frequencies in a graphical manner is
with a _bar chart_ (aka barplot or bar graph). One bar per distinct
category with the height of the bar representing the frequency (or percent)
of the data that fall into that category. 

```{r, fig.align='center', fig.width=4, fig.height=4}
ggplot(email, aes(number)) + geom_bar() + ylab("Frequency") + xlab("Size of number in email") + 
  ggtitle("Frequency of emails by size of the number") 
```

#### Research Question: Do more than half of the emails flagged as spam contain numbers?
We are only interested in the emails that are flagged spam, and that 
contain any number, so let's do a little data cleaning first. 

```{r}
spam.num <- email %>% 
              filter(spam==1) %>%  
              mutate(hasnum = ifelse(number %in% c("big", "small"), 1, 0))
# Confirm recode
table(spam.num$number, spam.num$hasnum, useNA="always")
```

* What is the proportion of spam emails that contain numbers? 
Since we created `hasnum` as a binary indicator, we can calculate the
sample proportion as the sample mean. 
```{r}
mean(spam.num$hasnum)
```
* Construct a 99% CI for the proportion of spam emails with numbers. 
Since this proportion follows the normal model we can conduct a t.test. 
```{r}
t.test(spam.num$hasnum, alternative = "two.sided", conf.level=.99)
```

Over half (59.4%, 95%CI: 52.7, 66.0) of emails that are flagged spam
contain numbers (p<.0001). This is statistically significantly larger
than half. 


[[top]](lec07_CategoricalDataAnalysis.html)



# Review: Difference of two proportions
* OpenIntro Section 6.2

Now let's consider comparisons of proportions in two independent samples. 

**Example**: Comparison of proportions of head injuries sustained in auto 
accidents by passengers wearing seat belts to those not wearing seat belts. 
You may have already guessed the form of the estimate: $\hat{p}_1 - \hat{p}_2$.

We are not going to go in depth into the calculations for the test statistic 
for a test of the difference in proportions. The OpenIntro textbook explains 
the assumptions and equations very well. Instead we are going to see how to 
use R to perform these calculations for us. 

Since the sample proportion can be calculated as the mean of a binary 
indicator variable, we can use the same `t.test` function in R
to conduct a hypothesis test and create a confidence interval.

## Tests of proportions using case level data
Do emails that contain numbers more likely to be spam? 

```{r}
email <- email %>% mutate(hasnum =ifelse(number %in% c("big", "small"), 0, 1))
t.test(spam~hasnum, data=email)
```

## Tests of proportions in R using summary numbers only
Sometimes you only have a summary table of numbers to go on, not the raw data. 
We can use the `prop.test()` function in R to conduct a test of equal proportions. 

This function calculates a test statistic and a p-value using a $\chi^2$ distribution. 

* The $\chi^2$ distribution is mathematically related to many other distributions. 
    * Specific of note here is that a $Z^{2}$ distribution has a $\chi^{2}_{1}$ distribution. 
    * Other relationships that are very useful: 
        * https://onlinecourses.science.psu.edu/stat414/node/154
        * https://en.wikipedia.org/wiki/Chi-squared_distribution#Relation_to_other_distributions

### Example 1: Spam vs Ham
Recall that 218 out of 367 (59%) of all emails that were flagged spam contained numbers. 
```{r}
table((email$number !="none"), email$spam, dnn=c("Contain numbers", "Spam"))
round(prop.table(table((email$number !="none"), email$spam, dnn=c("Contain numbers", "Spam")), 2)*100,2)
```
Is this proportion is significantly more than half by calling `prop.test()`. 

```{r}
prop.test(x=218, n=367, p=.5)
```

Significantly more than half (59%, 95%CI 54.2%-64.4%) of emails that were
flagged as spam contain numbers (p<.0004).


### Example 2: Are mammograms helpful?
Open Intro: 6.2.3

Test whether there was a difference in breast cancer deaths in the mammogram 
and control groups. By entering in $x$ and $n$ as vectors we can test 
equivelance of these two proportions. The assumptions for using the normal model 
for this test have been discussed in detail in the textbook. 

```{r}
prop.test(x=c(500, 505), n=c(44925, 44910))
```

The interval for the difference in proportions covers zero and the p-value
for the test is 0.894, therefore the proportion of deaths due to breast 
cancer are equal in both groups. There is no indication from this data
that mammograms in addition to regular breast cancer screening, change
the risk of death compared to just the regular screening exams alone. 



[[top]](lec07_CategoricalDataAnalysis.html)

# Contingency tables

* Both the explanatory and the resopnse variables are categorical (Nominal or Ordinal)
* Tables representing all combinations of levels of explanatory and response variables
* A.k.a Two-way tables or _cross-tabs_
* Numbers in table represent Counts of the number of cases in each cell

```{r}
tab <- table(email$spam, email$number)
tab
```

* Row and column totals are called Marginal counts

```{r}
addmargins(tab)
```

#### Cell percents
A simple `prop.table()` shows the cell percents. 
All cells add up to 1. The `mosaicplot` is a visual
representation of these percentages. The larger the 
box the larger the proportion. 
```{r}
prop.table(tab)
addmargins(prop.table(tab))
mosaicplot(tab)
```

We will come back to these mosaicplots later. 

#### Row percents
Here, the percents add up to 1 across the rows. 
The reference group (denominator) is the row category.  
```{r}
row.pct <- round(prop.table(tab, 1)*100, 2)
addmargins(row.pct, 2)
```
* 13.9% _of non-spam emails_ contain big numbers
* 40.6% _of spam emails_ contain no numbers
* 74.8% _of non-spam emails_ contain small numbers. 

#### Base graphics
Does "ok", but it depends on how you set up your table (rows vs columns),
and you  have to do more work to get a reasonable legend and y axis. 
```{r}
barplot(tab, beside=TRUE, legend=rownames(tab))
```

#### GGplot2
Requires the data to be aggregated first, then specify the heights
of the bars as a new variable. 
```{r}
library(reshape2)
melted_tab <- melt(tab)
colnames(melted_tab) <- c("Spam", "Number", "count")
melted_tab
ggplot(melted_tab, aes(x = factor(Spam), y= count, fill = Number)) + 
  geom_bar(stat="identity", width=.5, position = "dodge")  + 
  scale_x_discrete("Type of Email", labels=c("Ham", "Spam")) + 
  ylab("Frequency") 
```


#### Column percents
Here, the percents add up to 1 down the columns. 
The reference group (denominator) is the column category.  
```{r}
col.pct <- round(prop.table(tab, 2)*100, 2)
addmargins(col.pct,1)
```
* 90.8% _of emails with big numbers_ are not spam
* 27.1% _of emails with no numbers_ are spam
* 94.1% _of emails with small numbers_ are not spam

```{r}
ggplot(melted_tab, aes(x = Number, y= count, fill = factor(Spam))) + 
  geom_bar(stat="identity", width=.5, position = "dodge")  + 
  xlab("Size of number in email") + ylab("Frequency") + 
  scale_fill_discrete("Type of Email", labels=c("Ham", "Spam")) 
```

#### Summary / Take home message
It is very important to be clear as to what comparison you (or the researcher)
are interested in making. Sometimes both directions are equally important, 
but often there is one primary direction that is of interest. 


[[top]](lec07_CategoricalDataAnalysis.html)

# Side Note: Chi-Squared Distribution
Before we get into measures of, and tests for association we need to introduce
the $\chi^{2}$ distribution. 

* Controlled by a degrees of freedom parameter (df)
* Special case of the gamma distribution (One of the most commonly used 
  statistical distributions)
* The sample variance has a $\chi^{2}_{n-1}$ distribution.  
* The sum of $k$ independent standard normal distributions has a $\chi^{2}_{k}$ distribution. 
* The ANOVA F-statistic is the ratio of two $\chi^{2}$ distributions divided by 
  their respective degrees of freedom. 
* Is used in many statistical tests for categorical data. 
* Is always positive (it's squared!)
    - High numbers result in low p-values


# Measures of Association
* Watch this 6 minute Marin Stats Lectures: https://www.youtube.com/watch?v=V_YNPQoAyCc

We will consider two measures of association in this class. 

* Relative Risk
* Odds Ratio

These both are calculated on a 2x2 contingency table similar to the following: 

```{r, echo=FALSE, results='asis'}
nnnn <- matrix(c("$n_{11}$", "$n_{12}$", "$n_{1.}$", 
                 "$n_{21}$", "$n_{22}$", "$n_{2.}$", 
                 "$n_{.1}$", "$n_{.2}$", "$n_{..}$"), nrow=3, byrow=TRUE,  
          dimnames = list(c("Exposed", "Not-Exposed", "Total"), c("Diseased", "Not-Diseased", "Total")))
print(xtable(nnnn, align='cccc'), type='html')
```


Sometimes the cell contents are abbreviated as:
```{r, echo=FALSE, results='asis'}
abcd <- matrix(c("a", "b", "c", "d"), nrow=2,  
          dimnames = list(c("Exposed", "Not-Exposed"), c("Diseased", "Not-Diseased")))
print(xtable(abcd, align='ccc'), type='html')
```


## Relative Risk

The **Relative Risk (RR)** or **Risk Ratio** is the ratio of the probability of an 
event occuring in an exposed group compared to the probabilty of 
an event occuring in a non-exposed group. 

* Asymptotically approaches the OR for small probabilities. 
* Often used in cohort studies and randomized control trials. 

Consider sample proportions Diseases within Exposed and Non-exposed groups.
$$\hat{\pi}_{1} = \frac{n_{11}}{n_{1.}} \qquad \mbox{and} \qquad \hat{\pi}_{2} = \frac{n_{21}}{n_{2.}}$$

The Relative Risk is calculated as 

$$RR = \frac{\hat{\pi}_{1}}{\hat{\pi}_{2}} \qquad \mbox{or} \qquad \frac{a/(a+b)}{c/(c+d)}$$

with variance 
$$V = \frac{1-\hat{\pi}_{1}}{n_{11}} + \frac{1-\hat{\pi}_{2}}{n_{21}}$$


## Odds Ratio 

The **Odds Ratio (OR)** is a way to quantify how strongly the presence
or absence of a characteristic affects the presence or absence of a
second characteristic. 

* Often used in case-control studies
* The main interpretable estimate generated from logistic regression

The **Odds of an event** is the probability it occurs divided by the 
probability it does not occur. 

$$ odds_{1} = \frac{n_{11}/n_{1.}}{n_{12}/n_{1.}} = \frac{n_{11}}{n_{12}} $$
$$ odds_{2} = \frac{n_{21}/n_{2.}}{n_{22}/n_{2.}} = \frac{n_{21}}{n_{22}} $$

The **Odds Ratio** for group 1 compared to group 2 is the ratio of the two 
odds written above: 

$$OR = \frac{odds_{1}}{odds_{2}} = \frac{n_{11}n_{22}}{n_{12}n_{21}} \qquad \mbox{or} \qquad \frac{ad}{bc}$$

with variance $V = n^{-1}_{11} + n^{-1}_{12} + n^{-1}_{21} + n^{-1}_{22}$. 

## Confidence Intervals

Neither the Risk Ratio nor the Odds Ratio are linear functions, so a 95% CI 
for the population estimates are not your typical $\hat{\theta} \pm 1.96\sqrt{Var(\hat{\theta})}$.

Instead they are calculated as the point estimate $\hat{\theta}$ times $e$ 
raised to the $\pm 1.96$ times the standard deviation of the estimate. 

$$(\hat{\theta}e^{-1.96*\sqrt{V}}, \hat{\theta}e^{1.96*\sqrt{V}})$$



## Example: Are emails with numbers in them more likely to be flagged as spam? 
Reconsider the 2x2 table that compares emails flagged as spam to
those containing numbers. 

```{r}
table(email$hasnum, email$spam, dnn=c("Has Number", "Spam"))
```

Note that both the columns and rows are swapped when compared to the a/b/c/d format. 
For ease of interpretation I will recreate the table manually. 
```{r}
tab_sn <- matrix(c(149, 218, 400, 3154), nrow=2, byrow=T, 
                 dimnames = list(c("Has Num", "No Num"), c("Spam", "Ham")))
tab_sn
```

Now I use the `epi.2by2` function contained in the `epiR` package to calculate
the Odds Ratio, the Risk Ratio, and their respective confidence intervals. 
```{r}
library(epiR)
epi.2by2(tab_sn)
```

* Emails contaiing numbers are 3.6 (3.09, 4.21) times as likely as emails 
  without numbers to be flagged as spam.
* Emails containing numbers have 5.4 (4.27, 6.80) times the odds of being
  flagged as spam compared to emails without numbers in them. 

Both intervals are greater than 1, therefore the event (spam) is statistically
more likely to occur in the exposed group (has num) than in the control (no num) (p<.0001). 
The p-value for the Wald $\chi^{2}$ test is <.0001. 

* Mathematical reference for the Wald test Statistic http://www.statlect.com/Wald_test.htm 


[[top]](lec07_CategoricalDataAnalysis.html)

# Tests of association

* Watch this 3 minute Marin Stats Lecture: https://www.youtube.com/watch?v=POiHEJqmiC0

## Pearsons' Chi-Square Test

<!-- Can be used for nominal or ordinal explanatory and response variables
Variables can have any number of distinct levels
Tests whether the distribution of the response variable is the same for each level of the explanatory variable (H0: No association between the variables
r = # of levels of explanatory variable
c = # of levels of response variable 

Intuition behind test statistic
Obtain marginal distribution of outcomes for the response variable
Apply this common distribution to all levels of the explanatory variable, by multiplying each proportion by the corresponding sample size
Measure the difference between actual cell counts and the expected cell counts in the previous step


-->

http://inspire.stat.ucla.edu/unit_13/


### Testing Homogeneity
prop.test(table(email$number, email$spam))

### Testing Goodness of Fit

### Testing Independence

Uses the Pearson $\chi^{2}$ test statistic = Sum of squared residuals. 
mosaicplot(tab, shade=TRUE)
http://www.datavis.ca/online/mosaics/about.html

* Blue (positive residuals) = More frequent than expected
* Red (negative residuals) = Less frequent than expected. 


## Other common tests of note for contingency tables. 
* McNemarâ€™s Test for Paired Samples
* Fishers exact test for when cell sizes are small (<5-10)
* Interrater reliability: Concordant and Discordant Pairs


[[top]](lec07_CategoricalDataAnalysis.html)

# On Your Own
For all hypothesis tests you must: 

- Clearly state what your null and alternative hypothesis.  
- Discuss your assumptions
- Show your R code to conduct the test and any data management required prior to the test.
- Write the conclusion of the statistical test in context of the problem. 

##### On Your Own
1. Using the student `survey` data where the variable `smoker` is a binary indicator 
   of smoking, test if males smoke more than females. _Hint: check your output 
   carefully and consider if the difference was taken in the desired direction_
<!--
```{r}
library(MASS)
survey$yessmoker <- ifelse(survey$Smoke !="Never", 1, 0)
t.test(yessmoker ~ Sex , data=survey, alternative = "less")
```
--->
2. Anti-tumor necrosis factor $\alpha$ (TNF$\alpha$) drugs are a class of drugs
   that are commonly used to treat inflammatory conditions such as arthritis. 
   However, these drugs tend to be associated with an increased risk of 
   infectious complications. 
   [Bergstrom, et al (2004)](http://onlinelibrary.wiley.com/doi/10.1002/art.20454/abstract) 
   conducted a study to test the hypothesis that patients on these drugs 
   are at increased risk for coccidiomycosis (a fungal pneumonia). Calculate 
   and interpret the RR with 95% confidence interval.  Here are the tabular results. 
   
```{r, echo=FALSE, results='asis'}
tnf <- matrix(c(7, 240, 4, 734), nrow=2, byrow=TRUE,  
          dimnames = list(c("TNF", "Other"), c("COC", "No COC")))
print(xtable(tnf, align='ccc'), type='html')
``` 

   
   
    
    
    