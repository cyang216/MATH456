---
title: "Lec 02: Linear Regression Analysis"
author: "MATH 456 - Spring 2016"
output:
  html_document:
    highlight: pygments
    theme: spacelab
  pdf_document: default
---
```{r,echo=FALSE, warning=FALSE, message=FALSE}
library(knitr); library(rmarkdown);
opts_chunk$set(warning=FALSE, message=FALSE) 
```

```{r results="asis", echo=FALSE}
source("C:/Github/MATH456/stylesheets/custom.R")
```

# Assigned Reading
Afifi: Chapters 6-7

# Simple Regression and Correlation (_Afifi Ch 6_)

## Aims
* Describe the relationship between an independent variable X and a continuous
  dependent variable $Y$ as a straight line. The textbook discusses two cases: 
    - Fixed-$X$: values of $X$ are preselected by investigator
    - Variable-$X$: have random sample of $(X,Y)$ values
    - Calculations are the same, 
* Draw inferences regarding this relationship
* Predict value of $Y$ for a given value of $X$

## Mathmatical Model
* The mean of $Y$ values at any given $X$ is $\beta_{0} + \beta_{1} X$
* The variance of $Y$ values at any $X$ is $\sigma^2$ (same for all X)
* $Y$ values are normally distributed at any given $X$ (need for inference)

![Figure 6.2](slr_graph.png)

## Parameter Estimates
* Estimate the slope $\beta_{1}$ and intercept $\beta_{0}$ using least-squares methods.
* The residual mean squared error (RMSE) is an estimate of the variance $s^{2}$
* Typically interested in inference on $\beta_{1}$
    - Assume no relationship between $X$ and $Y$ $(H_{0}: \beta_{1}=0)$ 
      until there is reason to believe there is one 
      $(H_{0}: \beta_{1} \neq 0)$

## Interval estimation
* Everything is estimated with some degree of error
* Confidence intervals for the mean of $Y$
* Prediction intervals for an individual $Y$ 

Which one is wider? Why?

## Corelation Coefficient
* The correlation coefficient $\rho$ measures the strength of association
  between $X$ and $Y$ in the _population_.
* $\sigma^{2} = VAR(Y|X)$ is the variance of $Y$ for a specific $X$.
* $\sigma_{y}^{2} = VAR(Y)$ is the variance of $Y$ for all $X$'s.

$$ \sigma^{2} = \sigma_{y}^{2}(1-\rho^{2})$$
$$ \rho^{2} = \frac{\sigma_{y}^{2} - \sigma^{2}}{\sigma_{y}^{2}}$$

* $\rho^{2}$ = reduction in variance of Y associated with knowledge of X/original variance of Y
* **Coefficient of Determiniation**: $100\rho^{2}$ = % of variance of Y “associated with X” or “explained by X”
* Caution: association vs. causation.

### Example: Lung Function
_Note: The data management markdown file for this data set can be found [here](data/dm_lung.Rmd).
you will need to download the raw data, and this data management file, update the file locations
and run it on your machine to create the analysis data set._

_Section 6.3_
1. Read in the analysis data set for the lung function. 
```{r}
fev <- read.delim("C:/GitHub/MATH456/data/Lung_020716.txt", sep="\t", header=TRUE)
```

2. Create a scatterplot of FEV versus height for fathers. 
   Add a blue linear regression line and red lowess line.
   Add appropriate plot titles and axes labels.
   [R Cookbook reference](http://www.cookbook-r.com/Graphs/Scatterplots_(ggplot2)/)

```{r}
library(ggplot2)
qplot(y=FFEV1, x=FHEIGHT, geom="point", data=fev, xlab="Height", ylab="FEV1", 
      main="Scatter Diagram with Regression (blue) and Lowess (red) Lines 
      of FEV1 Versus Height for Fathers.") + 
      geom_smooth(method="lm", se=FALSE, col="blue") + 
      geom_smooth(se=FALSE, col="red") 
```

There does appear to be a tendency for taller men to have higher FEV1. 

7. Fit a linear model and report the regression parameter estimates. 
```{r}
model <- lm(FFEV1 ~ FHEIGHT, data=fev)
summary(model)
```
The least squares equation is $Y = -4.087 + 0.118X$.

8. Test for a significant relationship between height and FEV. Include a p-value and 
a confidence interval for the parameter estimate in your conclusion. 
```{r}
confint(model)
```
For ever inch taller a father is, his FEV1 measurement significantly increases by .12 (95%CI: .09, .15, p<.0001).  
The correlation between FEV1 and height is $\sqrt{.2544}$ = 0.5. 

9. Predict the FEV for a 6' and 6'4" male. 
```{r}
newdata <- data.frame(FHEIGHT=c(60, 64))
predict(model, newdata, interval="confidence")
predict(model, newdata, interval="prediction")
```

Why didn't I create a prediction for the 5' male? Hint, look at the range of height values below. 
```{r}
summary(fev$FHEIGHT)
```

## Assumptions of Linear Regression
* Homogeneity of variance (same $\sigma^{2}$)
    - Not extremely serious
    - Can use transformations to achieve it
* Normal residuals
    - Slight departures OK
    - Can use transformations to achieve it
* Randomness / Independence
    - Very serious
    - Can use hierarchical models for clustered samples
* Linear relationship
    - Slight departures OK
    - Can use transformations to achieve it

Assess the model fit and assumptions using graphical measures. 
```{r}
par(mfrow=c(2,2))
plot(model)
```

## What to watch out for
* Representative sample 
* Range of prediction should match observed range of X in sample
* Use of nominal or ordinal, rather than interval or ratio data
* Errors-in-variables
* Correlation does not imply causation 
* Violation of assumptions
* Influential points 
* Appropriate model



##### On Your Own: 
Write your responses in a new Markdown file named *userid_ch6.rmd*.

Problem 6.2, 6.7, 

# Multiple Regression and Correlation (_Afifi Ch 7_)


##### On Your Own
Write your responses in a new Markdown file named *userid_ch7.rmd*.


